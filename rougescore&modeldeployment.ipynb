{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fbac05b-56e4-4670-816e-822482f1c5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Summary:\n",
      "two men across the Greater Toronto Area say they lost thousands of dollars on vacation in Mexico. \"I stepped out of the taxi and immediately got a text from RBC saying $2,300 had been charged to my Visa,\" said Glenn Egan, who travelled to Mexico with his family in March of this year.\n",
      "\n",
      "ROUGE Scores:\n",
      "ROUGE-1: 0.3387\n",
      "ROUGE-2: 0.1311\n",
      "ROUGE-L: 0.2419\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "# Ensure that the NLTK sentence tokenizer is available\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Load the PEGASUS model and tokenizer\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Function to generate a summary using T5\n",
    "def generate_t5_summary(text):\n",
    "    num_beams = 25  # Further increase beams for more diverse summaries\n",
    "    length_penalty = 1.0  # Neutral to balance summary length\n",
    "    no_repeat_ngram_size = 2  # Allow for more bigram coverage\n",
    "    max_length = 150  # Focus on concise yet informative summaries\n",
    "    min_length = 80  # Ensure summary includes core content\n",
    "    do_sample = False\n",
    "\n",
    "    t5_inputs = t5_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    t5_summary_ids = t5_model.generate(t5_inputs, max_length=max_length, min_length=min_length, \n",
    "                                       num_beams=num_beams, length_penalty=length_penalty, \n",
    "                                       no_repeat_ngram_size=no_repeat_ngram_size, \n",
    "                                       do_sample=do_sample, early_stopping=True)\n",
    "    t5_summary = t5_tokenizer.decode(t5_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return t5_summary\n",
    "\n",
    "# Function to generate a summary using PEGASUS\n",
    "def generate_pegasus_summary(text):\n",
    "    num_beams = 25\n",
    "    length_penalty = 1.2\n",
    "    no_repeat_ngram_size = 2\n",
    "    max_length = 150\n",
    "    min_length = 80\n",
    "    do_sample = False\n",
    "\n",
    "    pegasus_inputs = pegasus_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
    "    pegasus_summary_ids = pegasus_model.generate(pegasus_inputs['input_ids'], max_length=max_length, min_length=min_length, \n",
    "                                                 num_beams=num_beams, length_penalty=length_penalty, \n",
    "                                                 no_repeat_ngram_size=no_repeat_ngram_size, \n",
    "                                                 do_sample=do_sample, early_stopping=True)\n",
    "    pegasus_summary = pegasus_tokenizer.decode(pegasus_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return pegasus_summary\n",
    "\n",
    "# Function to generate a combined summary with an emphasis on bigrams\n",
    "def generate_weighted_combined_summary(text, weight_t5=0.4, weight_pegasus=0.6):\n",
    "    t5_summary = generate_t5_summary(text)\n",
    "    pegasus_summary = generate_pegasus_summary(text)\n",
    "\n",
    "    # Tokenize summaries into sentences\n",
    "    t5_sentences = nltk.sent_tokenize(t5_summary)\n",
    "    pegasus_sentences = nltk.sent_tokenize(pegasus_summary)\n",
    "\n",
    "    # Combine sentences with a focus on maximizing bigram overlap\n",
    "    combined_sentences = []\n",
    "    combined_sentences.extend(t5_sentences[:int(len(t5_sentences) * weight_t5)])\n",
    "    combined_sentences.extend(pegasus_sentences[:int(len(pegasus_sentences) * weight_pegasus)])\n",
    "\n",
    "    # Reorder sentences to maximize bigram overlap (use n-gram analysis if needed)\n",
    "    combined_summary = \" \".join(combined_sentences)\n",
    "    \n",
    "    return combined_summary\n",
    "\n",
    "# Function to calculate ROUGE scores\n",
    "def calculate_rouge_scores(generated_summary, reference_summary):\n",
    "    scores = rouge.compute(predictions=[generated_summary], references=[reference_summary])\n",
    "    return {\n",
    "        \"ROUGE-1\": scores['rouge1'],\n",
    "        \"ROUGE-2\": scores['rouge2'],\n",
    "        \"ROUGE-L\": scores['rougeL']\n",
    "    }\n",
    "\n",
    "# Provided article text\n",
    "text_to_summarize = \"\"\"\n",
    "Two men across the Greater Toronto Area are speaking out after they said they lost thousands of dollars on vacation in Mexico.\n",
    "\n",
    "\"They said it's my word versus their word. So it's my word versus a scammer's word,\" Adam Attard, of Mississauga, told CTV News Toronto. Attard was vacationing with his girlfriend near Cancun, Mexico, in early July.\n",
    "\n",
    "Attard recalled an individual telling him he was at the wrong terminal when they arrived at the airport for their flight home, so they took a short ride in a shuttle to reach the correct one. Before he left the shuttle, Attard said the driver locked the doors and demanded payment by credit card.\n",
    "\n",
    "\"We couldn't get out of the van. There were no visible latches or locks to open the door. The [shuttle] driver said, 'You are not leaving until you pay the $3,'\" said Attard.\n",
    "\n",
    "When Attard was told the payment didn't go through, the driver then said he accepted cash. However, Attard said his credit card was immediately charged $3,142.\n",
    "\n",
    "Attard said he contacted the Royal Bank of Canada's Visa customer care line and was initially told he would be refunded the money, but later, he was told he wouldn't be.\n",
    "\n",
    "\"After I was told I would be covered, I was told because I punched in my PIN and did not get a receipt, they would not refund me anything,\" said Attard.\n",
    "\n",
    "Glenn Egan of Toronto also travelled to Mexico in March of this year. He was visiting Mexico City with his family when they decided to take a taxi back from a museum to his hotel.\n",
    "\n",
    "Egan said the taxi ride should have cost about $15, but he was charged $2,300 on his credit card.\n",
    "\n",
    "According to Egan, the driver also demanded he pay with a credit card and then claimed the charges didn't go through, so he accepted cash. A minute later, Egan's bank notified him he had been scammed.\n",
    "\n",
    "\"I stepped out of the taxi and immediately got a text from RBC saying $2,300 had been charged to my Visa,\" said Egan.\n",
    "\n",
    "Egan said he'd contacted Visa right away to dispute the charge, but after four months of trying, he was told he would not be given a refund.\n",
    "\n",
    "\"At the end, they said I didn't get a receipt and without one, I can't dispute the charges,\" said Egan. \"They say with Visa you're protected against fraud and the fact they won't step up is infuriating. It's not 20 bucks, it's $2,300.\"\n",
    "\n",
    "An RBC spokesperson told CTV News Toronto that it reviews each report of potential fraud on a case-by-case basis and urges its customers to take precautions when receiving or transferring funds.\n",
    "\n",
    "\"While we cannot comment on the specifics of this situation, we can advise that we take this matter seriously and are working with our client directly throughout the process to keep them informed,\" the spokesperson said.\n",
    "\n",
    "\"Scams are increasingly sophisticated, and we work closely with industry associations, government and law enforcement to prevent, detect and investigate fraud, including when it happens in other jurisdictions.\"\n",
    "\n",
    "Not long after Egan reached out to CTV News, he was told he would receive a full refund of his $2,300. Attard was also refunded his $3,142.\n",
    "\n",
    "To avoid being caught in a fake taxi scam, make sure you're in a licenced cab or shuttle and book through a trusted source, like a hotel or tour company. You should also ask in advance if you can pay in cash and how much the charge will be.\n",
    "\"\"\"\n",
    "\n",
    "# Reference summary\n",
    "reference_summary = \"\"\"\n",
    "Two men from the Greater Toronto Area were scammed during their vacations in Mexico, losing thousands of dollars. Adam Attard and Glenn Egan were both charged large sums by drivers who then claimed the charges didn't go through, leading to disputes with their banks. Eventually, both men were refunded after their cases were highlighted. Travelers are advised to use licensed transport and confirm payment methods to avoid such scams.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the combined summary\n",
    "combined_summary = generate_weighted_combined_summary(text_to_summarize, weight_t5=0.4, weight_pegasus=0.6)\n",
    "\n",
    "# Calculate the ROUGE scores\n",
    "rouge_scores = calculate_rouge_scores(combined_summary, reference_summary)\n",
    "\n",
    "# Print the results\n",
    "print(\"Combined Summary:\")\n",
    "print(combined_summary)\n",
    "print(\"\\nROUGE Scores:\")\n",
    "for key, score in rouge_scores.items():\n",
    "    print(f\"{key}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "795b5181-f319-49f7-acd0-aebbdeb68ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\alexi\\anaconda3\\lib\\site-packages (2.2.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: gradio in c:\\users\\alexi\\anaconda3\\lib\\site-packages (4.39.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\alexi\\anaconda3\\lib\\site-packages (4.42.3)\n",
      "Requirement already satisfied: evaluate in c:\\users\\alexi\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\alexi\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: torch in c:\\users\\alexi\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.111.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==1.1.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (1.1.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.23.4)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (6.4.0)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (1.24.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (3.10.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.5.5)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (2.0.7)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio) (0.30.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio-client==1.1.1->gradio) (2023.10.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from gradio-client==1.1.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: dill in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: joblib in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.3.5)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.0.4)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from fastapi->gradio) (2.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from uvicorn[standard]>=0.12.0->fastapi->gradio) (0.22.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\alexi\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install flask gradio transformers evaluate nltk torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22141639-b765-4e83-9f5e-84ffb78839d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "# Ensure that the NLTK sentence tokenizer is available\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Load the PEGASUS model and tokenizer\n",
    "pegasus_model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
    "pegasus_tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Function to generate a summary using T5\n",
    "def generate_t5_summary(text):\n",
    "    num_beams = 25  # Further increase beams for more diverse summaries\n",
    "    length_penalty = 1.0  # Neutral to balance summary length\n",
    "    no_repeat_ngram_size = 2  # Allow for more bigram coverage\n",
    "    max_length = 150  # Focus on concise yet informative summaries\n",
    "    min_length = 80  # Ensure summary includes core content\n",
    "    do_sample = False\n",
    "\n",
    "    t5_inputs = t5_tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    t5_summary_ids = t5_model.generate(t5_inputs, max_length=max_length, min_length=min_length, \n",
    "                                       num_beams=num_beams, length_penalty=length_penalty, \n",
    "                                       no_repeat_ngram_size=no_repeat_ngram_size, \n",
    "                                       do_sample=do_sample, early_stopping=True)\n",
    "    t5_summary = t5_tokenizer.decode(t5_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return t5_summary\n",
    "\n",
    "# Function to generate a summary using PEGASUS\n",
    "def generate_pegasus_summary(text):\n",
    "    num_beams = 20\n",
    "    length_penalty = 1.2\n",
    "    no_repeat_ngram_size = 2\n",
    "    max_length = 150\n",
    "    min_length = 80\n",
    "    do_sample = False\n",
    "\n",
    "    pegasus_inputs = pegasus_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=512)\n",
    "    pegasus_summary_ids = pegasus_model.generate(pegasus_inputs['input_ids'], max_length=max_length, min_length=min_length, \n",
    "                                                 num_beams=num_beams, length_penalty=length_penalty, \n",
    "                                                 no_repeat_ngram_size=no_repeat_ngram_size, \n",
    "                                                 do_sample=do_sample, early_stopping=True)\n",
    "    pegasus_summary = pegasus_tokenizer.decode(pegasus_summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return pegasus_summary\n",
    "\n",
    "# Function to generate a combined summary with an emphasis on bigrams\n",
    "def generate_weighted_combined_summary(text, weight_t5=0.4, weight_pegasus=0.6):\n",
    "    t5_summary = generate_t5_summary(text)\n",
    "    pegasus_summary = generate_pegasus_summary(text)\n",
    "\n",
    "    # Tokenize summaries into sentences\n",
    "    t5_sentences = nltk.sent_tokenize(t5_summary)\n",
    "    pegasus_sentences = nltk.sent_tokenize(pegasus_summary)\n",
    "\n",
    "    # Combine sentences with a focus on maximizing bigram overlap\n",
    "    combined_sentences = []\n",
    "    combined_sentences.extend(t5_sentences[:int(len(t5_sentences) * weight_t5)])\n",
    "    combined_sentences.extend(pegasus_sentences[:int(len(pegasus_sentences) * weight_pegasus)])\n",
    "\n",
    "    # Reorder sentences to maximize bigram overlap (use n-gram analysis if needed)\n",
    "    combined_summary = \" \".join(combined_sentences)\n",
    "    \n",
    "    return combined_summary\n",
    "\n",
    "# Define the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=generate_weighted_combined_summary,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"textbox\",\n",
    "    title=\"Text Summarizer with T5 and PEGASUS\",\n",
    "    description=\"Enter a text to generate its summary using a combined T5 and PEGASUS model.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WvlLVtLUK76"
      },
      "outputs": [],
      "source": [
        "# Function to adjust padding\n",
        "def adjust_padding(examples, max_length=512):\n",
        "    # Adjust inputs\n",
        "    inputs = tokenizer.pad(\n",
        "        {\"input_ids\": examples[\"input_ids\"], \"attention_mask\": examples[\"attention_mask\"]},\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # Adjust labels\n",
        "    labels = tokenizer.pad(\n",
        "        {\"input_ids\": examples[\"labels\"]},\n",
        "        padding=\"max_length\",\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # Convert tensors to lists\n",
        "    examples[\"input_ids\"] = inputs[\"input_ids\"].tolist()\n",
        "    examples[\"attention_mask\"] = inputs[\"attention_mask\"].tolist()\n",
        "    examples[\"labels\"] = labels[\"input_ids\"].tolist()\n",
        "    return examples"
      ]
    }
  ]
}
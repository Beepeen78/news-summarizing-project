# Load the model and tokenizer for inference
model = T5ForConditionalGeneration.from_pretrained('saved_model/t5-small')
tokenizer = T5Tokenizer.from_pretrained('saved_model/t5-small')
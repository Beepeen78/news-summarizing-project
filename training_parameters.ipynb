from transformers import T5ForConditionalGeneration, Trainer, TrainingArguments

# Load the model
model = T5ForConditionalGeneration.from_pretrained('t5-small')

# Adjust training parameters
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=1,  # Reduce the number of epochs
    per_device_train_batch_size=8,  # Increase the batch size if you have enough GPU memory
    per_device_eval_batch_size=8,
    warmup_steps=100,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=10,
    eval_strategy="epoch",
    fp16=True,  # Use mixed precision training if supported by your hardware
    disable_tqdm=False,  # Ensure tqdm progress bar is enabled
    report_to="none"  # Ensure no integration with external logging services
)
